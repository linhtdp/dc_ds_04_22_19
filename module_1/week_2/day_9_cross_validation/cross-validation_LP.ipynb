{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic: Cross Validation in predictive modeling\n",
    "\n",
    "\n",
    "## Problem\n",
    "\n",
    "When you do `train-test-split` you are sampling randomly to identify the train and test datasets.\n",
    "\n",
    "![img](train-test-examp.png)\n",
    "\n",
    "But what about **sampling error**? What if you get a **BAD SAMPLE**?!\n",
    "\n",
    "![bad](https://media.giphy.com/media/cJjQJWU70DSuHzx4oR/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Task\n",
    "![map](map.png) \n",
    "\n",
    "Build a multivariate Ordinary Least Squares regression model to predict \"TARGET_deathRate\"with a more robust model validation method, cross-validation.<br>\n",
    "We have data aggregated from a number of sources including the American Community Survey (census.gov), clinicaltrials.gov, and cancer.gov. Most of the data preparation process can be viewed here.\n",
    "\n",
    "\n",
    "## Learning Goals:\n",
    "\n",
    "- Describe the elements of  K-fold Cross validation \n",
    "- Recognize how K-fold cross validation is superior to normal validation testing\n",
    "- Apply K-fold cross validation to a dataset\n",
    "- Apply K-fold cross validation to Module 1 project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation\n",
    "Let us talk about `training` and `testing.`\n",
    "\n",
    "![train-test](why-train-test.png)\n",
    "\n",
    "We split to prevent:\n",
    "\n",
    "![fit-pit](overfit_underfit.png)\n",
    "(found on [this blog](https://rmartinshort.jimdo.com/2019/02/17/overfitting-bias-variance-and-leaning-curves/)). \n",
    "\n",
    "But what if by random chance of your training dataset split - your training data isn't representative? what if it includes some wacky data?\n",
    "\n",
    "![but what if](bad-split.png)\n",
    "\n",
    "k-fold averages that out, and also keeps from “overfitting” and “underfitting.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goal 1: Describe the elements of K-fold Cross validation \n",
    "\n",
    "In the context of modeling, K-fold cross validation sits under the Stage 6- Predictive Modeling, in the 7 stage Data Science Lifecycle.\n",
    "\n",
    "![chart](chart.png)\n",
    "\n",
    "K-fold cross validation essentially helps us increase the accuracy of any Machine learning model. It does this by taking the average of the results of training and testing data from given dataset. This in turn is by dividing the dataset into several (“k”) folds. Then, Training data on “k-1” folds and testing on “kth” fold. Repeat this “k” times and average the result.\n",
    "\n",
    "![cross-val](cross-val-graphic.png)\n",
    "(graphic from [here](https://towardsdatascience.com/cross-validation-70289113a072) )\n",
    "\n",
    "We can compare the resultant accuracy by taking the average of accuracy calculated during each of the folds. This tends to give a more real picture of the machine learning model performance. \n",
    "\n",
    "The cross validation technique can be used to compare the performance of different machine learning models on the same data set. To understand this point better, let us consider the following example.\n",
    "\n",
    "Go through [this blog](https://towardsdatascience.com/5-reasons-why-you-should-use-cross-validation-in-your-data-science-project-8163311a1e79) to hit the topic home.\n",
    "\n",
    "## Learning Goal 2:  Explain to Greg\n",
    "![img2](thinking.jpeg)\n",
    "\n",
    "You've hired Greg to build models for you. He's stressed and trying to tell you there isn't enough time to do a cross validation and that one train-test split should be enough.\n",
    "\n",
    "Write down what you would say to Greg and then tell it to your neighbor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goal 3: Applying k-fold cross validation\n",
    "\n",
    "### Try the code in each of these articles:\n",
    "\n",
    "### One half of room:\n",
    "This is a good tech blog:\n",
    "\n",
    "[this blog is a good one](https://machinelearningmastery.com/k-fold-cross-validation/)\n",
    "\n",
    "### Other half of room:\n",
    "[another good example](https://medium.com/datadriveninvestor/k-fold-cross-validation-6b8518070833)\n",
    "\n",
    "\n",
    "### Task: \n",
    "Write the most important  parts of code from each post on the board & then discuss\n",
    "\n",
    "- What did you need to specify?\n",
    "- What new libraries did you use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model to predict cancer\n",
    "\n",
    "\n",
    "```\n",
    "cancer_rates = pd.read_csv('https://query.data.world/s/5ylxfjp6oymzhuhhzwmlbqxzcw6etz')\n",
    "\n",
    "households = pd.read_csv('https://download.data.world/s/3nopgtdm2fwjgidovkostutkfitlps')\n",
    "```\n",
    "\n",
    "[Here is the documentatiopn](https://data.world/exercises/linear-regression-exercise-1/workspace/data-dictionary) for this data.\n",
    "\n",
    "Integrate this new knowledge of k-fold cross validation to build a model and calculate the average performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "#look at the data\n",
    "#maybe scale it \n",
    "#indentify a\n",
    "#intialize linear regression\n",
    "#decide how many folds that you want to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cancer_rates = pd.read_csv('https://query.data.world/s/5ylxfjp6oymzhuhhzwmlbqxzcw6etz')\n",
    "households = pd.read_csv('https://download.data.world/s/3nopgtdm2fwjgidovkostutkfitlps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3220 entries, 0 to 3219\n",
      "Data columns (total 4 columns):\n",
      "statefips           3220 non-null int64\n",
      "countyfips          3220 non-null int64\n",
      "avghouseholdsize    3220 non-null float64\n",
      "geography           3220 non-null object\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 100.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3047 entries, 0 to 3046\n",
      "Data columns (total 33 columns):\n",
      "avganncount                3047 non-null float64\n",
      "avgdeathsperyear           3047 non-null int64\n",
      "target_deathrate           3047 non-null float64\n",
      "incidencerate              3047 non-null float64\n",
      "medincome                  3047 non-null int64\n",
      "popest2015                 3047 non-null int64\n",
      "povertypercent             3047 non-null float64\n",
      "studypercap                3047 non-null float64\n",
      "binnedinc                  3047 non-null object\n",
      "medianage                  3047 non-null float64\n",
      "medianagemale              3047 non-null float64\n",
      "medianagefemale            3047 non-null float64\n",
      "geography                  3047 non-null object\n",
      "percentmarried             3047 non-null float64\n",
      "pctnohs18_24               3047 non-null float64\n",
      "pcths18_24                 3047 non-null float64\n",
      "pctsomecol18_24            762 non-null float64\n",
      "pctbachdeg18_24            3047 non-null float64\n",
      "pcths25_over               3047 non-null float64\n",
      "pctbachdeg25_over          3047 non-null float64\n",
      "pctemployed16_over         2895 non-null float64\n",
      "pctunemployed16_over       3047 non-null float64\n",
      "pctprivatecoverage         3047 non-null float64\n",
      "pctprivatecoveragealone    2438 non-null float64\n",
      "pctempprivcoverage         3047 non-null float64\n",
      "pctpubliccoverage          3047 non-null float64\n",
      "pctpubliccoveragealone     3047 non-null float64\n",
      "pctwhite                   3047 non-null float64\n",
      "pctblack                   3047 non-null float64\n",
      "pctasian                   3047 non-null float64\n",
      "pctotherrace               3047 non-null float64\n",
      "pctmarriedhouseholds       3047 non-null float64\n",
      "birthrate                  3047 non-null float64\n",
      "dtypes: float64(28), int64(3), object(2)\n",
      "memory usage: 785.6+ KB\n"
     ]
    }
   ],
   "source": [
    "households.info()\n",
    "cancer_rates.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avganncount</th>\n",
       "      <th>avgdeathsperyear</th>\n",
       "      <th>target_deathrate</th>\n",
       "      <th>incidencerate</th>\n",
       "      <th>medincome</th>\n",
       "      <th>popest2015</th>\n",
       "      <th>povertypercent</th>\n",
       "      <th>studypercap</th>\n",
       "      <th>binnedinc</th>\n",
       "      <th>medianage</th>\n",
       "      <th>...</th>\n",
       "      <th>pctprivatecoveragealone</th>\n",
       "      <th>pctempprivcoverage</th>\n",
       "      <th>pctpubliccoverage</th>\n",
       "      <th>pctpubliccoveragealone</th>\n",
       "      <th>pctwhite</th>\n",
       "      <th>pctblack</th>\n",
       "      <th>pctasian</th>\n",
       "      <th>pctotherrace</th>\n",
       "      <th>pctmarriedhouseholds</th>\n",
       "      <th>birthrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1397.0</td>\n",
       "      <td>469</td>\n",
       "      <td>164.9</td>\n",
       "      <td>489.8</td>\n",
       "      <td>61898</td>\n",
       "      <td>260131</td>\n",
       "      <td>11.2</td>\n",
       "      <td>499.748204</td>\n",
       "      <td>(61494.5, 125635]</td>\n",
       "      <td>39.3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.6</td>\n",
       "      <td>32.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>81.780529</td>\n",
       "      <td>2.594728</td>\n",
       "      <td>4.821857</td>\n",
       "      <td>1.843479</td>\n",
       "      <td>52.856076</td>\n",
       "      <td>6.118831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173.0</td>\n",
       "      <td>70</td>\n",
       "      <td>161.3</td>\n",
       "      <td>411.6</td>\n",
       "      <td>48127</td>\n",
       "      <td>43269</td>\n",
       "      <td>18.6</td>\n",
       "      <td>23.111234</td>\n",
       "      <td>(48021.6, 51046.4]</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.8</td>\n",
       "      <td>43.6</td>\n",
       "      <td>31.1</td>\n",
       "      <td>15.3</td>\n",
       "      <td>89.228509</td>\n",
       "      <td>0.969102</td>\n",
       "      <td>2.246233</td>\n",
       "      <td>3.741352</td>\n",
       "      <td>45.372500</td>\n",
       "      <td>4.333096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.0</td>\n",
       "      <td>50</td>\n",
       "      <td>174.7</td>\n",
       "      <td>349.7</td>\n",
       "      <td>49348</td>\n",
       "      <td>21026</td>\n",
       "      <td>14.6</td>\n",
       "      <td>47.560164</td>\n",
       "      <td>(48021.6, 51046.4]</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5</td>\n",
       "      <td>34.9</td>\n",
       "      <td>42.1</td>\n",
       "      <td>21.1</td>\n",
       "      <td>90.922190</td>\n",
       "      <td>0.739673</td>\n",
       "      <td>0.465898</td>\n",
       "      <td>2.747358</td>\n",
       "      <td>54.444868</td>\n",
       "      <td>3.729488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>427.0</td>\n",
       "      <td>202</td>\n",
       "      <td>194.8</td>\n",
       "      <td>430.4</td>\n",
       "      <td>44243</td>\n",
       "      <td>75882</td>\n",
       "      <td>17.1</td>\n",
       "      <td>342.637253</td>\n",
       "      <td>(42724.4, 45201]</td>\n",
       "      <td>42.8</td>\n",
       "      <td>...</td>\n",
       "      <td>40.3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>91.744686</td>\n",
       "      <td>0.782626</td>\n",
       "      <td>1.161359</td>\n",
       "      <td>1.362643</td>\n",
       "      <td>51.021514</td>\n",
       "      <td>4.603841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>26</td>\n",
       "      <td>144.4</td>\n",
       "      <td>350.1</td>\n",
       "      <td>49955</td>\n",
       "      <td>10321</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>(48021.6, 51046.4]</td>\n",
       "      <td>48.3</td>\n",
       "      <td>...</td>\n",
       "      <td>43.9</td>\n",
       "      <td>35.1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>22.7</td>\n",
       "      <td>94.104024</td>\n",
       "      <td>0.270192</td>\n",
       "      <td>0.665830</td>\n",
       "      <td>0.492135</td>\n",
       "      <td>54.027460</td>\n",
       "      <td>6.796657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   avganncount  avgdeathsperyear  target_deathrate  incidencerate  medincome  \\\n",
       "0       1397.0               469             164.9          489.8      61898   \n",
       "1        173.0                70             161.3          411.6      48127   \n",
       "2        102.0                50             174.7          349.7      49348   \n",
       "3        427.0               202             194.8          430.4      44243   \n",
       "4         57.0                26             144.4          350.1      49955   \n",
       "\n",
       "   popest2015  povertypercent  studypercap           binnedinc  medianage  \\\n",
       "0      260131            11.2   499.748204   (61494.5, 125635]       39.3   \n",
       "1       43269            18.6    23.111234  (48021.6, 51046.4]       33.0   \n",
       "2       21026            14.6    47.560164  (48021.6, 51046.4]       45.0   \n",
       "3       75882            17.1   342.637253    (42724.4, 45201]       42.8   \n",
       "4       10321            12.5     0.000000  (48021.6, 51046.4]       48.3   \n",
       "\n",
       "   ...  pctprivatecoveragealone  pctempprivcoverage pctpubliccoverage  \\\n",
       "0  ...                      NaN                41.6              32.9   \n",
       "1  ...                     53.8                43.6              31.1   \n",
       "2  ...                     43.5                34.9              42.1   \n",
       "3  ...                     40.3                35.0              45.3   \n",
       "4  ...                     43.9                35.1              44.0   \n",
       "\n",
       "   pctpubliccoveragealone   pctwhite  pctblack  pctasian  pctotherrace  \\\n",
       "0                    14.0  81.780529  2.594728  4.821857      1.843479   \n",
       "1                    15.3  89.228509  0.969102  2.246233      3.741352   \n",
       "2                    21.1  90.922190  0.739673  0.465898      2.747358   \n",
       "3                    25.0  91.744686  0.782626  1.161359      1.362643   \n",
       "4                    22.7  94.104024  0.270192  0.665830      0.492135   \n",
       "\n",
       "   pctmarriedhouseholds  birthrate  \n",
       "0             52.856076   6.118831  \n",
       "1             45.372500   4.333096  \n",
       "2             54.444868   3.729488  \n",
       "3             51.021514   4.603841  \n",
       "4             54.027460   6.796657  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_rates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "import matplotlib.pyplot as plt\n",
    "X = cancer_rates[['avganncount']]\n",
    "y = cancer_rates['target_deathrate']\n",
    "cv_5_results = np.mean(cross_val_score(linreg, X,  y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "cv_10_results = np.mean(cross_val_score(linreg, X, y, cv=10, scoring=\"neg_mean_squared_error\"))\n",
    "cv_20_results = np.mean(cross_val_score(linreg, X, y, cv=20, scoring=\"neg_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-764.0498763494331\n",
      "-765.5585490425608\n",
      "-761.5520479838815\n"
     ]
    }
   ],
   "source": [
    "print(cv_5_results)\n",
    "print(cv_10_results)\n",
    "print(cv_20_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avganncount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>427.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>428.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>146.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4025.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>113.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>740.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3438.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2265.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>251.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1390.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>305.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1081.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>134.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>958.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>499.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>564.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3017</th>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3021</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3022</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3023</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3025</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3026</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3027</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3028</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3031</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3032</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3041</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3044</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3045</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>1962.667684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3047 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      avganncount\n",
       "0     1397.000000\n",
       "1      173.000000\n",
       "2      102.000000\n",
       "3      427.000000\n",
       "4       57.000000\n",
       "5      428.000000\n",
       "6      250.000000\n",
       "7      146.000000\n",
       "8       88.000000\n",
       "9     4025.000000\n",
       "10     113.000000\n",
       "11     740.000000\n",
       "12      55.000000\n",
       "13    3438.000000\n",
       "14    2265.000000\n",
       "15     251.000000\n",
       "16    1390.000000\n",
       "17      32.000000\n",
       "18     305.000000\n",
       "19    1081.000000\n",
       "20     134.000000\n",
       "21     958.000000\n",
       "22      94.000000\n",
       "23     499.000000\n",
       "24     152.000000\n",
       "25      80.000000\n",
       "26     164.000000\n",
       "27     564.000000\n",
       "28      50.000000\n",
       "29      70.000000\n",
       "...           ...\n",
       "3017    87.000000\n",
       "3018  1962.667684\n",
       "3019  1962.667684\n",
       "3020  1962.667684\n",
       "3021  1962.667684\n",
       "3022  1962.667684\n",
       "3023  1962.667684\n",
       "3024  1962.667684\n",
       "3025  1962.667684\n",
       "3026  1962.667684\n",
       "3027  1962.667684\n",
       "3028  1962.667684\n",
       "3029  1962.667684\n",
       "3030  1962.667684\n",
       "3031  1962.667684\n",
       "3032  1962.667684\n",
       "3033  1962.667684\n",
       "3034  1962.667684\n",
       "3035  1962.667684\n",
       "3036  1962.667684\n",
       "3037  1962.667684\n",
       "3038  1962.667684\n",
       "3039  1962.667684\n",
       "3040  1962.667684\n",
       "3041  1962.667684\n",
       "3042  1962.667684\n",
       "3043  1962.667684\n",
       "3044  1962.667684\n",
       "3045  1962.667684\n",
       "3046  1962.667684\n",
       "\n",
       "[3047 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_rates[['avganncount']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment\n",
    "\n",
    "Did they achieve all the learning goals from the start? How do you confirm? You can use many different methods:\n",
    "\n",
    "Review questions? (make into quiz)\n",
    "\n",
    "- What is “training” and “testing” \n",
    "- What is underfitting?\n",
    "- What is overfitting?\n",
    "- What is the data science lifecycle? (students should be able to articulate the 7 steps in the - pie chart above)\n",
    "- What is k-fold cross validation?\n",
    "\n",
    "\n",
    "Why is it useful?\n",
    "\n",
    "### Reflection/Key Takeaways\n",
    "\n",
    "\n",
    "In machine learning, it is always a good idea to play around with different predictive models and their parameters to arrive at the best choice. Fine-tuning your machine learning model is helpful in achieving good results, and of course, cross validation helps you know if you are on the right track to get a good predictive model.\n",
    "\n",
    "\n",
    "_Limitations of Cross Validation_ <br>\n",
    "For cross validation to give some meaningful results, the training set and the validation set are required to be drawn from the same population. Also, human biases need to be controlled, or else cross validation will not be fruitful.\n",
    "\n",
    "_**Other Applications**_\n",
    "\n",
    "_Compare Performance_<br>\n",
    "Suppose you want to make a classifier for the MNIST data set, which consists of hand-written numerals from 0 to 9. You are considering using either K Nearest Neighbours (KNN) or Support Vector Machine (SVM). To compare the performance of the two machine learning models on the given data set, you can use cross validation. This will help you determine which predictive model you should choose working with for the MNIST data set.\n",
    "Cross validation can also be used for selecting suitable parameters. The example mentioned below will illustrate this point well.\n",
    "\n",
    "_Fine-tune Parameters_<br>\n",
    "Suppose you have to build a K Nearest Neighbours (KNN) classifier for the MNIST data set. To use this classifier, you should provide an appropriate value of the parameter k to the classifier. Choosing the value of k intuitively is not a good idea (beware of overfitting!). You can play around with different values of the parameter k and use cross validation to estimate the performance of the predictive model corresponding to each k. You should finally go ahead with the value of k that gives the best performance of the predictive model on the given data set.\n",
    "For the K Nearest Neighbours (KNN) classifier, you can even choose different metrics (default is ‘minkowski’ if you use ‘KNeighborsClassifier’ of sklearn). So you can use cross validation to determine which metric is the best for the data set you have.\n",
    "\n",
    "_References_\n",
    "- https://machinelearningmastery.com/k-fold-cross-validation/\n",
    "- https://towardsdatascience.com/5-reasons-why-you-should-use-cross-validation-in-your-data-science-project-8163311a1e79\n",
    "- https://www.researchgate.net/post/What_is_the_purpose_of_performing_cross-validation\n",
    "- https://medium.com/datadriveninvestor/k-fold-cross-validation-6b8518070833\n",
    "- https://www.cs.tau.ac.il/~nin/Courses/NC05/pr_l13.pdf\n",
    "- https://magoosh.com/data-science/k-fold-cross-validation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
